{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Biclustering Algorithm \n",
    "Proposed by Odibat & Reddy, 2014 in **Efficient mining of discriminative co-clusters from gene\n",
    "expression data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import consensus_score\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import glob as glob\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycodestyle\n",
    "# !pip install pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 1 - Coherence Measure H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle\n",
    "class CoherenceMeasure(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n, self.m = data.shape\n",
    "        self.xiJ = np.mean(data, axis=1)\n",
    "        self.xIj = np.mean(data, axis=0)\n",
    "        self.xIJ = np.mean(data)\n",
    "        self._H = None\n",
    "\n",
    "    @property\n",
    "    def H(self):\n",
    "        if self._H is None:\n",
    "            print(\"Computing coherence measure\")\n",
    "            self._H = self._compute_H()\n",
    "            print(\"H value: \" + str(self._H))\n",
    "        return self._H\n",
    "    \n",
    "    def _compute_H(self):\n",
    "        H = 0\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                H += (self.data[i, j] - self.xIj[j] -\n",
    "                      self.xiJ[i] + self.xIJ)**2\n",
    "        H *= 1.0/math.fabs(self.m*self.n)\n",
    "        H = 1 - H\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for Coherence Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.87426777  0.23264193  0.49488635 ...,  0.43157877  0.23196908\n",
      "   0.94369486]\n",
      " [ 0.19279925  0.26426963  0.27284129 ...,  0.57197032  0.18804943\n",
      "   0.14928147]\n",
      " [ 0.2857795   0.08995835  0.62883951 ...,  0.88306076  0.69264995\n",
      "   0.07203184]\n",
      " ..., \n",
      " [ 0.11157932  0.12408198  0.92286694 ...,  0.22565307  0.24864138\n",
      "   0.61205152]\n",
      " [ 0.90678421  0.03268699  0.78134208 ...,  0.03998985  0.30385596\n",
      "   0.58319474]\n",
      " [ 0.44018822  0.30425343  0.97171935 ...,  0.8163351   0.19616119\n",
      "   0.44353343]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data = np.random.random((50, 50))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coherence measure\n",
      "H value: 0.919034599018\n",
      "H = 0.919034599018\n"
     ]
    }
   ],
   "source": [
    "# Testing Coherence\n",
    "coherence_measure = CoherenceMeasure(data)\n",
    "print(\"H = \" + str(coherence_measure.H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 2 - Positive and negative correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: rows x and y and J columns\n",
    "# output: positive and negative correlations\n",
    "\n",
    "\n",
    "class PositiveNegativeCorrelation(object):\n",
    "    def __init__(self, x, y, J):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._J = J\n",
    "        self._x_mean = np.mean(x)\n",
    "        self._y_mean = np.mean(y)\n",
    "        self._H_pos = None\n",
    "        self._H_neg = None\n",
    "\n",
    "    @property\n",
    "    def H_pos(self):\n",
    "        if self._H_pos is None:\n",
    "            # print(\"Computing H positive...\")\n",
    "            self._H_pos = self._compute_H_pos()\n",
    "            # print(\"H positive value: \" + str(self._H_pos))\n",
    "        return self._H_pos\n",
    "\n",
    "    @property\n",
    "    def H_neg(self):\n",
    "        if self._H_neg is None:\n",
    "            # print(\"Computing H negative...\")\n",
    "            self._H_neg = self._compute_H_neg()\n",
    "            # print(\"H negative value: \" + str(self._H_neg))\n",
    "        return self._H_neg\n",
    "\n",
    "    def _compute_H_pos(self):\n",
    "        H_pos = 0\n",
    "        for j in range(self._J):\n",
    "            aux = (((self._x[j] - self._x_mean) -\n",
    "                    (self._y[j] - self._y_mean))/2.0)**2\n",
    "            H_pos += aux\n",
    "        H_pos *= 1.0/math.fabs(self._J)\n",
    "        H_pos = 1 - H_pos\n",
    "        return H_pos\n",
    "\n",
    "    def _compute_H_neg(self):\n",
    "        H_neg = 0\n",
    "        for j in range(self._J):\n",
    "            aux = (((self._x[j] - self._x_mean) +\n",
    "                    (self._y[j] - self._y_mean))/2.0)**2\n",
    "            H_neg += aux\n",
    "        H_neg *= 1.0/math.fabs(self._J)\n",
    "        H_neg = 1 - H_neg\n",
    "        return H_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for positive and negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row x [ 0.55317234  0.9115416   0.91860091  0.75331959  0.75805542]\n",
      "Row y [ 0.74474406  0.58136519  0.30983438  0.05064852  0.87376606]\n",
      "J value 5\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((5))\n",
    "y = np.random.random((5))\n",
    "J = 5\n",
    "print(\"Row x \" + str(x))\n",
    "print(\"Row y \" + str(y))\n",
    "print(\"J value \" + str(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H positive 0.966631986963\n",
      "\n",
      "H negative 0.980095606363\n"
     ]
    }
   ],
   "source": [
    "# Testing correlation\n",
    "positive_negative_correlation = PositiveNegativeCorrelation(x,y,J)\n",
    "print(\"H positive \" + str(positive_negative_correlation.H_pos))\n",
    "print()\n",
    "print(\"H negative \" + str(positive_negative_correlation.H_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 3 - Pair-based coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for pair-based coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "# input: co-cluster X of I rows and J columns\n",
    "# output: paired-based coherence\n",
    "\n",
    "\n",
    "class PairBasedCoherence(object):\n",
    "    def __init__(self, X):\n",
    "        self._X = np.array(X)\n",
    "        self._I, self._J = X.shape\n",
    "        self._HP = None\n",
    "\n",
    "    @property\n",
    "    def HP(self):\n",
    "        if self._HP is None:\n",
    "            # print(\"Calculating Pair based coherence..\")\n",
    "            self._HP = self._compute_HP_()\n",
    "            # print(\"Paired based coherence value: \" + str(self._HP))\n",
    "        return self._HP\n",
    "\n",
    "    def _compute_HP_(self):\n",
    "        HP = 0\n",
    "        for i in range(self._I):\n",
    "            for j in range(i+1, self._I):\n",
    "                if (i==j): \n",
    "                    break\n",
    "                x = self._X[i]\n",
    "                y = self._X[j]\n",
    "                correlation = PositiveNegativeCorrelation(x, y,self._J)\n",
    "                H0 = correlation.H_pos\n",
    "                # H0 = max(correlation.H_pos,correlation.H_neg)\n",
    "                HP += H0\n",
    "        HP *= math.fabs(1.0)/(math.fabs(self._I)*(math.fabs(self._I)-1))\n",
    "        return HP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.78843657  0.06128162  0.79977716 ...,  0.26129019  0.13525645\n",
      "   0.87491824]\n",
      " [ 0.94498083  0.40018565  0.96886247 ...,  0.25191983  0.74471593\n",
      "   0.1092453 ]\n",
      " [ 0.76537123  0.20014459  0.04921407 ...,  0.18377568  0.09959164\n",
      "   0.11048272]\n",
      " ..., \n",
      " [ 0.57449934  0.1567446   0.40824512 ...,  0.83777677  0.57231899\n",
      "   0.91215927]\n",
      " [ 0.04595223  0.17971602  0.10857193 ...,  0.16420614  0.39903575\n",
      "   0.75012004]\n",
      " [ 0.4275483   0.73545074  0.15424827 ...,  0.96183812  0.08360435\n",
      "   0.21051396]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.random((50, 50))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H value 0.479876204073\n"
     ]
    }
   ],
   "source": [
    "pair_based_coherence = PairBasedCoherence(data)\n",
    "print(\"H value \" + str(pair_based_coherence.HP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence for a new z in in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Define H for a new term 'z' in X\n",
       "$$\n",
       "H_{1}(I,J,X,z) =H_{0}(I,J,X) \\cdot \\frac{(I-1)}{(I+1)} + \\frac{|2|}{(I)(I+1)} \\cdot \\sum_{x \\epsilon X} {h(x,z,J)}\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "Define H for a new term 'z' in X\n",
    "$$\n",
    "H_{1}(I,J,X,z) =H_{0}(I,J,X) \\cdot \\frac{(I-1)}{(I+1)} + \\frac{|2|}{(I)(I+1)} \\cdot \\sum_{x \\epsilon X} {h(x,z,J)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPOOC\n",
    "\n",
    "This algorithm is proposed to efficiently extract the most coherent and large co-clusters that area arbitrarily positioned in the data matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 1 RAPOOC (D,k,l,K)\n",
    "Input: Data matrix D, number of row clusters (k), number of column clusters (l), number of optimized co-clusters (K)\n",
    "\n",
    "Output: A set of K co-clusters({X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.029469</td>\n",
       "      <td>0.45006</td>\n",
       "      <td>0.207910</td>\n",
       "      <td>0.052621</td>\n",
       "      <td>0.57575</td>\n",
       "      <td>0.42221</td>\n",
       "      <td>0.59412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.357910</td>\n",
       "      <td>0.62144</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.679850</td>\n",
       "      <td>0.12174</td>\n",
       "      <td>0.76694</td>\n",
       "      <td>0.27906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.447640</td>\n",
       "      <td>0.18441</td>\n",
       "      <td>0.836500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.33869</td>\n",
       "      <td>0.96056</td>\n",
       "      <td>0.56005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.781750</td>\n",
       "      <td>0.96066</td>\n",
       "      <td>0.040275</td>\n",
       "      <td>0.154620</td>\n",
       "      <td>0.54363</td>\n",
       "      <td>0.70729</td>\n",
       "      <td>0.62836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.322800</td>\n",
       "      <td>0.42936</td>\n",
       "      <td>0.204720</td>\n",
       "      <td>0.650460</td>\n",
       "      <td>0.37645</td>\n",
       "      <td>0.76164</td>\n",
       "      <td>0.52247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0        1         2         3        4        5        6\n",
       "0  0.029469  0.45006  0.207910  0.052621  0.57575  0.42221  0.59412\n",
       "1  0.357910  0.62144  0.579620  0.679850  0.12174  0.76694  0.27906\n",
       "2  0.447640  0.18441  0.836500  1.000000  0.33869  0.96056  0.56005\n",
       "3  0.781750  0.96066  0.040275  0.154620  0.54363  0.70729  0.62836\n",
       "4  0.322800  0.42936  0.204720  0.650460  0.37645  0.76164  0.52247"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TestData/SimulatedDataCoherence/RandData.csv',header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BisectingClusterer(object):\n",
    "    def __init__(self, data):\n",
    "        if data is not None:\n",
    "            self._data = np.array(data)\n",
    "            self._I, self._J = self._data.shape\n",
    "        else:\n",
    "            print(\"Empty data\")\n",
    "    \n",
    "    @property\n",
    "    def centroids(self):\n",
    "        return self._centroids\n",
    "\n",
    "    def fit(self):\n",
    "        self._centroids = self._compute_centroids_()\n",
    "        bisecting_indices = self._bisect_clusters_(self._centroids)\n",
    "        return bisecting_indices\n",
    "    \n",
    "    def _compute_centroids_(self):\n",
    "        max_correlation = 0\n",
    "        centroids = [0,0]\n",
    "        for i in range(self._I):\n",
    "            for j in range(i+1, self._I):\n",
    "                if (i == j):\n",
    "                    break\n",
    "                correlation = PositiveNegativeCorrelation(self._data[i],\n",
    "                                                          self._data[j],\n",
    "                                                          self._J).H_neg\n",
    "                if(correlation > max_correlation):\n",
    "                    max_correlation = correlation\n",
    "                    centroids[0] = i\n",
    "                    centroids[1] = j\n",
    "        return centroids\n",
    "\n",
    "    def _bisect_clusters_(self, centroids):\n",
    "        cluster_indices = np.zeros(self._I)\n",
    "        for i in range(self._I):\n",
    "            correlation0 = PositiveNegativeCorrelation(\n",
    "                self._data[centroids[0]], self._data[i],self._J).H_pos\n",
    "            correlation1 = PositiveNegativeCorrelation(\n",
    "                self._data[centroids[1]], self._data[i],self._J).H_pos\n",
    "            if(correlation0 <= correlation1):\n",
    "                cluster_indices[i] = 1\n",
    "        return cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rapooc(object):\n",
    "    def __init__(self, D, k, l, K):\n",
    "        self._D = np.array(D)\n",
    "        assert k>0 and l >0, \"invalid values, k>0 and l>0\"\n",
    "        self._k = k\n",
    "        self._l = l\n",
    "        assert K <= k*l and k>=1, \"invalid values, 1<= K <= k*l\"\n",
    "        self._K = K\n",
    "        self._rho = np.ones(D.shape[0])\n",
    "        self._gamma = np.ones(D.shape[1])\n",
    "        self._M, self._N = self._D.shape\n",
    "        self._cluster_H_values = None\n",
    "            \n",
    "    @property\n",
    "    def rho(self):\n",
    "        return self._rho\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return self._gamma\n",
    "    \n",
    "    @property\n",
    "    def bicluster_h_values(self):\n",
    "        return self._cluster_H_values\n",
    "\n",
    "    def initialize(self):\n",
    "        i = 1\n",
    "        j = 1\n",
    "        while (i < self._k or j < self._l):\n",
    "            if i < self._k:\n",
    "                i += 1\n",
    "                alpha = self._argmin_H_(self._rho, self._gamma,'row')\n",
    "                self._bisect_partitions_(self._D[np.where(self._rho==alpha)], self._rho, alpha, i,'row')\n",
    "            if j < self._l:\n",
    "                j += 1\n",
    "                beta = self._argmin_H_(self._rho,self._gamma, 'column')\n",
    "                self._bisect_partitions_((self._D.T)[np.where(self._gamma==beta)], self._gamma, beta, j,'column')   \n",
    "\n",
    "    def _argmin_H_(self, row_co_cluster, col_co_cluster,option='row'):\n",
    "        if (option=='row'):\n",
    "            data = self._D\n",
    "        else:\n",
    "            data = self._D.T\n",
    "        h_min = math.inf\n",
    "        min_cocluster = 1\n",
    "        map_array = np.int64(row_co_cluster if option == 'row' else col_co_cluster)\n",
    "        max_index_in_map = np.max(map_array)\n",
    "        for i in range(1,max_index_in_map):\n",
    "            if (list(map_array).count(i) < 2):\n",
    "                pass\n",
    "            else:\n",
    "                coherence = PairBasedCoherence(\n",
    "                    data[np.where((row_co_cluster if option == 'row' else col_co_cluster) == i)]).HP \n",
    "                if (coherence <= h_min):\n",
    "                    h_min = coherence\n",
    "                    min_cocluster = i\n",
    "        return min_cocluster\n",
    "\n",
    "    def _bisect_partitions_ (self, data, mapping_array, cluster_to_replace, new_cluster_index,option='row'):\n",
    "        clusterer = BisectingClusterer(data)\n",
    "        bisected_map = clusterer.fit()\n",
    "        bisected_map_index = 0\n",
    "        for i in range(0,len(mapping_array)):\n",
    "            if ((self._rho if option == 'row' else self._gamma)[i] == cluster_to_replace):\n",
    "                if (bisected_map[bisected_map_index] == 1.0):\n",
    "                    (self._rho if option == 'row' else self._gamma)[i] = new_cluster_index\n",
    "                bisected_map_index += 1\n",
    "                          \n",
    "    def core_coclustering(self):\n",
    "        # self.compute_H_values()\n",
    "        max_h_value = 0.0\n",
    "        h_values_repetitions = 0\n",
    "        flg_h_drop = False\n",
    "        \n",
    "        # simulated annealing?\n",
    "        self._rows_delta = 0.0\n",
    "        self._cols_delta = 0.0\n",
    "        manager = mp.Manager()\n",
    "        return_dict = manager.dict()\n",
    "        for i in range(0,10):   \n",
    "            \n",
    "            # '''\n",
    "            print (\"iter \" +str(i))\n",
    "            if (h_values_repetitions>20 or flg_h_drop):\n",
    "                break;\n",
    "                \n",
    "            # jobs\n",
    "            jobs = list()\n",
    "            jobs.append(mp.Process(target = self._arg_max_, args = ('row', return_dict)))\n",
    "            jobs.append(mp.Process(target = self._arg_max_, args = ('column', return_dict))) \n",
    "            \n",
    "            for job in jobs:\n",
    "                print(\"starting jobs\")\n",
    "                job.start()\n",
    "            \n",
    "            #join jobs\n",
    "            for job in jobs:\n",
    "                print(\"finishing jobs\")\n",
    "                job.join()\n",
    "            \n",
    "            '''\n",
    "            \n",
    "            \n",
    "            self._arg_max_('row')\n",
    "            print('% debug %')\n",
    "            self._arg_max_('column')\n",
    "            '''\n",
    "            \n",
    "            self._rows_delta = return_dict[0]\n",
    "            self._cols_delta = return_dict[1]\n",
    "            actual_h_value = return_dict[0] + return_dict[1]\n",
    "            print(\"% debug % rows delta \" + str(self._rows_delta) )\n",
    "            print(\"% debug % cols delta \" + str(self._cols_delta) )\n",
    "            print(\"h value: \" + str(actual_h_value))\n",
    "            if(actual_h_value > max_h_value):\n",
    "                max_h_value = actual_h_value\n",
    "                h_values_repetitions = 0\n",
    "                self._best_row_map = self._rho\n",
    "                self._best_col_map = self._gamma\n",
    "                \n",
    "                \n",
    "            elif (math.fabs(actual_h_value - max_h_value) <= 0.001):\n",
    "                h_values_repetitions += 1\n",
    "            else:\n",
    "                h_values_repetitions = 0\n",
    "                \n",
    "            if (h_values_repetitions > 5):\n",
    "                print(\"actual h value \" + str(actual_h_value))\n",
    "                print(\"max h value \" + str(max_h_value))\n",
    "                print(\"n repetitions \" + str(h_values_repetitions))\n",
    "                break\n",
    "        \n",
    "    def compute_H_values(self):\n",
    "        self._cluster_H_values = np.array([ [0.0] * int(max(self._rho) + 1)  \n",
    "                                           for _ in range(int(max(self._gamma) + 1))])\n",
    "        for i in range(1,int(max(self._rho) + 1)):\n",
    "            for j in range (1, int(max(self._gamma) + 1)):\n",
    "                coherence = PairBasedCoherence(self._D[np.ix_(np.where(self._rho == i)[0],\n",
    "                                                              np.where(self._gamma == j)[0])]).HP\n",
    "                self._cluster_H_values[i][j] = coherence\n",
    "            \n",
    "    def _row_clustering_(self):\n",
    "            self._rho = self._arg_max_('row')\n",
    "    \n",
    "    def _column_clustering_(self):\n",
    "            self._gamma = self._arg_max_('column')\n",
    "            \n",
    "    def _arg_max_(self,option = 'row',delta = None): \n",
    "        print(\" arg max \" + option)\n",
    "        if option == 'row':\n",
    "            mapping_array = self._rho\n",
    "            data = self._D\n",
    "        else:\n",
    "            mapping_array = self._gamma\n",
    "            data = self._D.T\n",
    "            \n",
    "        num_of_biclusters = int(np.max(mapping_array))\n",
    "        \n",
    "        # initial_optimum = reduce(lambda x,y: x + y, h_values[1:int(max(mapping_array))])\n",
    "        \n",
    "        total_delta = 0\n",
    "        for i in range (0,len(data)):\n",
    "            flg_keep = True\n",
    "            element = data[i]\n",
    "            element_cluster = int(mapping_array[i])\n",
    "            element_h = self._compute_single_h_term_(element_cluster, data, mapping_array)\n",
    "            optimal_delta = 0\n",
    "            if (list(mapping_array).count(element_cluster)>2):\n",
    "                no_element_h = self._compute_single_h_term_(element_cluster, data, mapping_array)\n",
    "                mapping_array[i] = 0\n",
    "                flg_keep = (math.fabs(element_h - no_element_h) <= 0.001 )\n",
    "            else: \n",
    "                flg_keep = True\n",
    "            optimal_cluster = 0\n",
    "            flg_h_rise = False\n",
    "            for cluster in range(1,int(max(mapping_array)) +1):\n",
    "                # print (\"% debug % \" + \" max clusters \"+ str(int(max(mapping_array))))\n",
    "                if (cluster == element_cluster):\n",
    "                    pass \n",
    "                else:\n",
    "                    if ((list(mapping_array).count(i)) > 2):\n",
    "                        mapping_array[i] = cluster\n",
    "                        cluster_size = list(mapping_array).count(cluster)\n",
    "                        h_delta = self._compute_single_h_term_(cluster, data, mapping_array)\n",
    "                        # print(\"% debug % option \" + str(option) + \" h_delta \" + str(h_delta))\n",
    "                        if (h_delta > optimal_delta):\n",
    "                            optimal_delta = h_delta\n",
    "                            optimal_cluster = cluster\n",
    "                            flg_h_rise = True\n",
    "            \n",
    "            # print(\"% debug % mapping cluster \" + str(optimal_cluster if \\\n",
    "                            # flg_h_rise else \\\n",
    "                            # (element_cluster if flg_keep else 0)))\n",
    "            mapping_array[i] =  optimal_cluster if \\\n",
    "                            flg_h_rise else \\\n",
    "                            (element_cluster if flg_keep else 0)\n",
    "            total_delta += optimal_delta\n",
    "        # print(\"% debug optimal%  \" + str(total_delta))\n",
    "        if option=='row':\n",
    "            delta[0] = total_delta\n",
    "            # print(\"% debug % inner rows delta \" + str(delta[0]))\n",
    "        else:\n",
    "            delta[1] = total_delta\n",
    "            # print(\"% debug % inner cols delta \" + str(delta[1]))\n",
    "        \n",
    "    def _compute_single_h_term_(self, cluster, data, mapping_array):\n",
    "        coherence = PairBasedCoherence(data[np.where(mapping_array == cluster)]).HP\n",
    "        return coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapooc = Rapooc(data,2,2,4)\n",
    "rapooc.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "starting jobs\n",
      "starting jobs\n",
      " arg max row\n",
      " arg max column\n",
      "finishing jobs\n"
     ]
    }
   ],
   "source": [
    "rapooc.core_coclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  2.,  1.,  2.,  1.,  2.])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapooc.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  1.,  2.,  1.,  2.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  1.,\n",
       "        2.,  2.,  1.,  2.,  2.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,  1.,\n",
       "        1.,  2.,  1.,  1.,  2.,  2.,  1.,  2.,  1.,  1.,  2.,  1.,  1.,\n",
       "        1.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,  2.,\n",
       "        2.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  1.,\n",
       "        1.,  2.,  2.,  1.,  2.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  1.,  2.,  1.,  1.,  1.,\n",
       "        2.,  2.,  1.,  1.,  1.,  1.,  2.,  2.,  2.])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapooc.rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rapooc.bicluster_h_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TestData/SimulatedDataCoherence/LowCoherence.csv',\n",
       " 'TestData/SimulatedDataCoherence/HighCoherenceMix.csv',\n",
       " 'TestData/SimulatedDataCoherence/MidCoherence.csv',\n",
       " 'TestData/SimulatedDataCoherence/RandData.csv',\n",
       " 'TestData/SimulatedDataCoherence/HighCoherence.csv',\n",
       " 'TestData/SimulatedDataCoherence/LowCoherenceMix.csv',\n",
       " 'TestData/SimulatedDataCoherence/MidCoherenceMix.csv']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "glob.glob('TestData/SimulatedDataCoherence/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(np.array([0,1,2,3,3,3,6,7,8]))\n",
    "a = d[np.whe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.013931 ,  0.49935  ],\n",
       "       [ 0.0067908,  0.50297  ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)[np.ix_([0,3],[1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Cl1:\n",
    "    def __init__(self):\n",
    "        self._arr =  np.array(np.array([0,1,2,3,3,3,6,7,8]))\n",
    "    \n",
    "    def calc(self):\n",
    "        num = 0\n",
    "        self._calc2(num)\n",
    "        print (self._arr)\n",
    "    \n",
    "    def _calc2(self,num):\n",
    "        n = self._arr\n",
    "        self._arr[0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 2 3 3 3 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "cl = Cl1()\n",
    "cl.calc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
