{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative Biclustering Algorithm \n",
    "Proposed by Odibat & Reddy, 2014 in **Efficient mining of discriminative co-clusters from gene\n",
    "expression data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import consensus_score\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import glob as glob\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycodestyle\n",
    "# !pip install pycodestyle_magic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 1 - Coherence Measure H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle\n",
    "class CoherenceMeasure(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.n, self.m = data.shape\n",
    "        self.xiJ = np.mean(data, axis=1)\n",
    "        self.xIj = np.mean(data, axis=0)\n",
    "        self.xIJ = np.mean(data)\n",
    "        self._H = None\n",
    "\n",
    "    @property\n",
    "    def H(self):\n",
    "        if self._H is None:\n",
    "            print(\"Computing coherence measure\")\n",
    "            self._H = self._compute_H()\n",
    "            print(\"H value: \" + str(self._H))\n",
    "        return self._H\n",
    "    \n",
    "    def _compute_H(self):\n",
    "        H = 0\n",
    "        for i in range(self.n):\n",
    "            for j in range(self.m):\n",
    "                H += (self.data[i, j] - self.xIj[j] -\n",
    "                      self.xiJ[i] + self.xIJ)**2\n",
    "        H *= 1.0/math.fabs(self.m*self.n)\n",
    "        H = 1 - H\n",
    "        return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for Coherence Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.67223392  0.05730369  0.58718702 ...,  0.46175495  0.35493749\n",
      "   0.12153704]\n",
      " [ 0.80887785  0.0451742   0.34966532 ...,  0.40622315  0.66183642\n",
      "   0.86556317]\n",
      " [ 0.67203729  0.12295668  0.59680418 ...,  0.018873    0.00771753\n",
      "   0.02325043]\n",
      " ..., \n",
      " [ 0.56439024  0.58408646  0.43073384 ...,  0.93899258  0.37981884\n",
      "   0.46816191]\n",
      " [ 0.58067125  0.9237371   0.55683491 ...,  0.34105763  0.52530834\n",
      "   0.23168843]\n",
      " [ 0.92655025  0.61445531  0.30605175 ...,  0.32990357  0.27647049\n",
      "   0.82275964]]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "data = np.random.random((50, 50))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing coherence measure\n",
      "H value: 0.919075202837\n",
      "H = 0.919075202837\n"
     ]
    }
   ],
   "source": [
    "# Testing Coherence\n",
    "coherence_measure = CoherenceMeasure(data)\n",
    "print(\"H = \" + str(coherence_measure.H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 2 - Positive and negative correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input: rows x and y and J columns\n",
    "# output: positive and negative correlations\n",
    "\n",
    "\n",
    "class PositiveNegativeCorrelation(object):\n",
    "    def __init__(self, x, y, J):\n",
    "        self._x = x\n",
    "        self._y = y\n",
    "        self._J = J\n",
    "        self._x_mean = np.mean(x)\n",
    "        self._y_mean = np.mean(y)\n",
    "        self._H_pos = None\n",
    "        self._H_neg = None\n",
    "\n",
    "    @property\n",
    "    def H_pos(self):\n",
    "        if self._H_pos is None:\n",
    "            # print(\"Computing H positive...\")\n",
    "            self._H_pos = self._compute_H_pos()\n",
    "            # print(\"H positive value: \" + str(self._H_pos))\n",
    "        return self._H_pos\n",
    "\n",
    "    @property\n",
    "    def H_neg(self):\n",
    "        if self._H_neg is None:\n",
    "            # print(\"Computing H negative...\")\n",
    "            self._H_neg = self._compute_H_neg()\n",
    "            # print(\"H negative value: \" + str(self._H_neg))\n",
    "        return self._H_neg\n",
    "\n",
    "    def _compute_H_pos(self):\n",
    "        H_pos = 0\n",
    "        for j in range(self._J):\n",
    "            aux = (((self._x[j] - self._x_mean) -\n",
    "                    (self._y[j] - self._y_mean))/2.0)**2\n",
    "            H_pos += aux\n",
    "        H_pos *= 1.0/math.fabs(self._J)\n",
    "        H_pos = 1 - H_pos\n",
    "        return H_pos\n",
    "\n",
    "    def _compute_H_neg(self):\n",
    "        H_neg = 0\n",
    "        for j in range(self._J):\n",
    "            aux = (((self._x[j] - self._x_mean) +\n",
    "                    (self._y[j] - self._y_mean))/2.0)**2\n",
    "            H_neg += aux\n",
    "        H_neg *= 1.0/math.fabs(self._J)\n",
    "        H_neg = 1 - H_neg\n",
    "        return H_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for positive and negative correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row x [ 0.93895089  0.11710639  0.32643905  0.4463099   0.27790122]\n",
      "Row y [ 0.89265351  0.64024148  0.12252775  0.09832966  0.67569515]\n",
      "J value 5\n"
     ]
    }
   ],
   "source": [
    "x = np.random.random((5))\n",
    "y = np.random.random((5))\n",
    "J = 5\n",
    "print(\"Row x \" + str(x))\n",
    "print(\"Row y \" + str(y))\n",
    "print(\"J value \" + str(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H positive 0.97120541997\n",
      "\n",
      "H negative 0.938972024938\n"
     ]
    }
   ],
   "source": [
    "# Testing correlation\n",
    "positive_negative_correlation = PositiveNegativeCorrelation(x,y,J)\n",
    "print(\"H positive \" + str(positive_negative_correlation.H_pos))\n",
    "print()\n",
    "print(\"H negative \" + str(positive_negative_correlation.H_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition 3 - Pair-based coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%pycodestyle\n",
    "\n",
    "# input: co-cluster X of I rows and J columns\n",
    "# output: paired-based coherence\n",
    "\n",
    "\n",
    "class PairBasedCoherence(object):\n",
    "    def __init__(self, X):\n",
    "        self._X = np.array(X)\n",
    "        self._I, self._J = X.shape\n",
    "        self._HP = None\n",
    "\n",
    "    @property\n",
    "    def HP(self):\n",
    "        if self._HP is None:\n",
    "            # print(\"Calculating Pair based coherence..\")\n",
    "            self._HP = self._compute_HP_()\n",
    "            # print(\"Paired based coherence value: \" + str(self._HP))\n",
    "        return self._HP\n",
    "\n",
    "    def _compute_HP_(self):\n",
    "        HP = 0\n",
    "        for i in range(self._I):\n",
    "            for j in range(i+1, self._I):\n",
    "                if (i==j): \n",
    "                    break\n",
    "                x = self._X[i]\n",
    "                y = self._X[j]\n",
    "                correlation = PositiveNegativeCorrelation(x, y,self._J)\n",
    "                H0 = correlation.H_pos\n",
    "                # H0 = max(correlation.H_pos,correlation.H_neg)\n",
    "                HP += H0\n",
    "        HP *= math.fabs(1.0)/(math.fabs(self._I)*(math.fabs(self._I)-1))\n",
    "        return HP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading test data for pair-based coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.3977003   0.41097539  0.92490071 ...,  0.42671076  0.15869944\n",
      "   0.23010634]\n",
      " [ 0.49486328  0.97289265  0.16373207 ...,  0.89676011  0.04975584\n",
      "   0.15219219]\n",
      " [ 0.07953859  0.39669464  0.60855359 ...,  0.22288821  0.38088693\n",
      "   0.24439542]\n",
      " ..., \n",
      " [ 0.74989084  0.61744422  0.4867372  ...,  0.24092302  0.87401566\n",
      "   0.86000712]\n",
      " [ 0.92654578  0.16637444  0.57521542 ...,  0.63668307  0.58885201\n",
      "   0.12506129]\n",
      " [ 0.07881462  0.87313589  0.57826627 ...,  0.04329009  0.76787694\n",
      "   0.09478329]]\n"
     ]
    }
   ],
   "source": [
    "data = np.random.random((50, 50))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paired based coherence value: 0.479712387334\n",
      "H value 0.479712387334\n"
     ]
    }
   ],
   "source": [
    "pair_based_coherence = PairBasedCoherence(data)\n",
    "print(\"H value \" + str(pair_based_coherence.HP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coherence for a new z in in X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "Define H for a new term 'z' in X\n",
       "$$\n",
       "H_{1}(I,J,X,z) =H_{0}(I,J,X) \\cdot \\frac{(I-1)}{(I+1)} + \\frac{|2|}{(I)(I+1)} \\cdot \\sum_{x \\epsilon X} {h(x,z,J)}\n",
       "$$"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "Define H for a new term 'z' in X\n",
    "$$\n",
    "H_{1}(I,J,X,z) =H_{0}(I,J,X) \\cdot \\frac{(I-1)}{(I+1)} + \\frac{|2|}{(I)(I+1)} \\cdot \\sum_{x \\epsilon X} {h(x,z,J)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAPOOC\n",
    "\n",
    "This algorithm is proposed to efficiently extract the most coherent and large co-clusters that area arbitrarily positioned in the data matrix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm 1 RAPOOC (D,k,l,K)\n",
    "Input: Data matrix D, number of row clusters (k), number of column clusters (l), number of optimized co-clusters (K)\n",
    "\n",
    "Output: A set of K co-clusters({X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.015521</td>\n",
       "      <td>0.013931</td>\n",
       "      <td>0.49935</td>\n",
       "      <td>0.98560</td>\n",
       "      <td>0.49268</td>\n",
       "      <td>0.006029</td>\n",
       "      <td>0.010850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.007915</td>\n",
       "      <td>0.49475</td>\n",
       "      <td>0.98089</td>\n",
       "      <td>0.49296</td>\n",
       "      <td>0.008737</td>\n",
       "      <td>0.007426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009314</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.50717</td>\n",
       "      <td>0.98620</td>\n",
       "      <td>0.49783</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.016632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003243</td>\n",
       "      <td>0.006791</td>\n",
       "      <td>0.50297</td>\n",
       "      <td>0.98170</td>\n",
       "      <td>0.50450</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.018980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010901</td>\n",
       "      <td>0.011237</td>\n",
       "      <td>0.49306</td>\n",
       "      <td>0.98213</td>\n",
       "      <td>0.50162</td>\n",
       "      <td>0.017864</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1        2        3        4         5         6\n",
       "0  0.015521  0.013931  0.49935  0.98560  0.49268  0.006029  0.010850\n",
       "1  0.007642  0.007915  0.49475  0.98089  0.49296  0.008737  0.007426\n",
       "2  0.009314  0.000106  0.50717  0.98620  0.49783  0.007664  0.016632\n",
       "3  0.003243  0.006791  0.50297  0.98170  0.50450  0.004663  0.018980\n",
       "4  0.010901  0.011237  0.49306  0.98213  0.50162  0.017864  0.001509"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('TestData/SimulatedDataCoherence/HighCoherenceMix.csv',header=None)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BisectingClusterer(object):\n",
    "    def __init__(self, data):\n",
    "        if data is not None:\n",
    "            self._data = np.array(data)\n",
    "            self._I, self._J = self._data.shape\n",
    "        else:\n",
    "            print(\"Empty data\")\n",
    "    \n",
    "    @property\n",
    "    def centroids(self):\n",
    "        return self._centroids\n",
    "\n",
    "    def fit(self):\n",
    "        self._centroids = self._compute_centroids_()\n",
    "        bisecting_indices = self._bisect_clusters_(self._centroids)\n",
    "        return bisecting_indices\n",
    "    \n",
    "    def _compute_centroids_(self):\n",
    "        max_correlation = 0\n",
    "        centroids = [0,0]\n",
    "        for i in range(self._I):\n",
    "            for j in range(i+1, self._I):\n",
    "                if (i == j):\n",
    "                    break\n",
    "                correlation = PositiveNegativeCorrelation(self._data[i],\n",
    "                                                          self._data[j],\n",
    "                                                          self._J).H_neg\n",
    "                if(correlation > max_correlation):\n",
    "                    max_correlation = correlation\n",
    "                    centroids[0] = i\n",
    "                    centroids[1] = j\n",
    "        return centroids\n",
    "\n",
    "    def _bisect_clusters_(self, centroids):\n",
    "        cluster_indices = np.zeros(self._I)\n",
    "        for i in range(self._I):\n",
    "            correlation0 = PositiveNegativeCorrelation(\n",
    "                self._data[centroids[0]], self._data[i],self._J).H_pos\n",
    "            correlation1 = PositiveNegativeCorrelation(\n",
    "                self._data[centroids[1]], self._data[i],self._J).H_pos\n",
    "            if(correlation0 <= correlation1):\n",
    "                cluster_indices[i] = 1\n",
    "        return cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rapooc(object):\n",
    "    def __init__(self, D, k, l, K):\n",
    "        self._D = np.array(D)\n",
    "        assert k>0 and l >0, \"invalid values, k>0 and l>0\"\n",
    "        self._k = k\n",
    "        self._l = l\n",
    "        assert K <= k*l and k>=1, \"invalid values, 1<= K <= k*l\"\n",
    "        self._K = K\n",
    "        self._rho = np.ones(D.shape[0])\n",
    "        self._gamma = np.ones(D.shape[1])\n",
    "        self._M, self._N = self._D.shape\n",
    "        self._cluster_H_values = None\n",
    "            \n",
    "    @property\n",
    "    def rho(self):\n",
    "        return self._rho\n",
    "    \n",
    "    @property\n",
    "    def gamma(self):\n",
    "        return self._gamma\n",
    "    \n",
    "    @property\n",
    "    def bicluster_h_values(self):\n",
    "        return self._cluster_H_values\n",
    "\n",
    "    def initialize(self):\n",
    "        i = 1\n",
    "        j = 1\n",
    "        while (i < self._k or j < self._l):\n",
    "            if i < self._k:\n",
    "                i += 1\n",
    "                alpha = self._argmin_H_(self._rho, self._gamma,'row')\n",
    "                self._bisect_partitions_(self._D[np.where(self._rho==alpha)], self._rho, alpha, i,'row')\n",
    "            if j < self._l:\n",
    "                j += 1\n",
    "                beta = self._argmin_H_(self._rho,self._gamma, 'column')\n",
    "                self._bisect_partitions_((self._D.T)[np.where(self._gamma==beta)], self._gamma, beta, j,'column')   \n",
    "\n",
    "    def _argmin_H_(self, row_co_cluster, col_co_cluster,option='row'):\n",
    "        if (option=='row'):\n",
    "            data = self._D\n",
    "        else:\n",
    "            data = self._D.T\n",
    "        h_min = math.inf\n",
    "        min_cocluster = 1\n",
    "        map_array = np.int64(row_co_cluster if option == 'row' else col_co_cluster)\n",
    "        max_index_in_map = np.max(map_array)\n",
    "        for i in range(1,max_index_in_map):\n",
    "            if (list(map_array).count(i) < 2):\n",
    "                pass\n",
    "            else:\n",
    "                coherence = PairBasedCoherence(\n",
    "                    data[np.where((row_co_cluster if option == 'row' else col_co_cluster) == i)]).HP \n",
    "                if (coherence <= h_min):\n",
    "                    h_min = coherence\n",
    "                    min_cocluster = i\n",
    "        return min_cocluster\n",
    "\n",
    "    def _bisect_partitions_ (self, data, mapping_array, cluster_to_replace, new_cluster_index,option='row'):\n",
    "        clusterer = BisectingClusterer(data)\n",
    "        bisected_map = clusterer.fit()\n",
    "        bisected_map_index = 0\n",
    "        for i in range(0,len(mapping_array)):\n",
    "            if ((self._rho if option == 'row' else self._gamma)[i] == cluster_to_replace):\n",
    "                if (bisected_map[bisected_map_index] == 1.0):\n",
    "                    (self._rho if option == 'row' else self._gamma)[i] = new_cluster_index\n",
    "                bisected_map_index += 1\n",
    "                          \n",
    "    def core_coclustering(self):\n",
    "        # self.compute_H_values()\n",
    "        max_h_value = 0.0\n",
    "        h_values_repetitions = 0\n",
    "        flg_h_drop = False\n",
    "        \n",
    "        #simulated annealing?\n",
    "        rows_delta = 0.0\n",
    "        cols_delta = 0.0\n",
    "        for i in range(0,10):        \n",
    "            \n",
    "            if (h_values_repetitions>20 or flg_h_drop):\n",
    "                break;\n",
    "                \n",
    "            # jobs\n",
    "            jobs = list()\n",
    "            jobs.append(mp.Process(target = self._arg_max_, args = ('row',rows_delta)))\n",
    "            jobs.append(mp.Process(target = self._arg_max_, args = ('column',cols_delta))) \n",
    "            \n",
    "            for job in jobs:\n",
    "                job.start()\n",
    "            \n",
    "            for job in jobs:\n",
    "                job.join()\n",
    "            \n",
    "            #join jobs\n",
    "            actual_h_value = rows_delta + cols_delta\n",
    "            \n",
    "            if(actual_h_value > max_h_value):\n",
    "                max_h_value = actual_h_value\n",
    "                h_values_repetitions = 0\n",
    "            elif (math.fabs(actual_h_value - max_h_value) <= 0.001):\n",
    "                h_values_repetitions += 1\n",
    "            else:\n",
    "                h_values_repetitions = 0\n",
    "                \n",
    "    def compute_H_values(self):\n",
    "        self._cluster_H_values = np.array([ [0.0] * int(max(self._rho) + 1)  \n",
    "                                           for _ in range(int(max(self._gamma) + 1))])\n",
    "        for i in range(1,int(max(self._rho) + 1)):\n",
    "            for j in range (1, int(max(self._gamma) + 1)):\n",
    "                coherence = PairBasedCoherence(self._D[np.ix_(np.where(self._rho == i)[0],\n",
    "                                                              np.where(self._gamma == j)[0])]).HP\n",
    "                self._cluster_H_values[i][j] = coherence\n",
    "            \n",
    "    def _row_clustering_(self):\n",
    "            self._rho = self._arg_max_('row')\n",
    "    \n",
    "    def _column_clustering_(self):\n",
    "            self._gamma = self._arg_max_('column')\n",
    "            \n",
    "    def _arg_max_(self,option = 'row',return_value = 0): \n",
    "        \n",
    "        if option == 'row':\n",
    "            mapping_array = self._rho\n",
    "            data = self._D\n",
    "        else:\n",
    "            mapping_array = self._gamma\n",
    "            data = self._D.T\n",
    "            \n",
    "        num_of_biclusters = int(np.max(mapping_array))\n",
    "        \n",
    "        # initial_optimum = reduce(lambda x,y: x + y, h_values[1:int(max(mapping_array))])\n",
    "        \n",
    "        total_delta = 0\n",
    "        for i in range (0,len(data)):\n",
    "            flg_keep = True\n",
    "            element = data[i]\n",
    "            element_cluster = int(mapping_array[i])\n",
    "            element_h = self._compute_single_h_term_(element_cluster, data, mapping_array)\n",
    "            optimal_delta = 0\n",
    "            if (list(mapping_array).count(element_cluster)>2):\n",
    "                no_element_h = self._compute_single_h_term_(element_cluster, data, mapping_array)\n",
    "                mapping_array[i] = 0\n",
    "                flg_keep = (math.fabs(element_h - no_element_h) <= 0.001 )\n",
    "            else: \n",
    "                flg_keep = True\n",
    "            optimal_cluster = 0\n",
    "            flg_h_rise = False\n",
    "            for cluster in range(1,int(max(mapping_array))):\n",
    "                if (cluster == element_cluster):\n",
    "                    pass \n",
    "                else:\n",
    "                    if ((list(mapping_array).count(i)) > 2):\n",
    "                        mapping_array[i] = cluster\n",
    "                        cluster_size = list(mapping_array).count(cluster)\n",
    "                        h_delta = self._compute_single_h_term_(cluster, data, mapping_array)\n",
    "                        if (h_delta > optimal_delta):\n",
    "                            optimal_delta = h_delta\n",
    "                            optimal_cluster = cluster\n",
    "                            flg_h_rise = True\n",
    "\n",
    "            mapping_array[i] =  optimal_cluster if \\\n",
    "                            flg_h_rise else \\\n",
    "                            (element_cluster if flg_keep else 0)\n",
    "            total_delta += optimal_delta\n",
    "        return_value = optimal_delta\n",
    "        \n",
    "    def _compute_single_h_term_(self, cluster, data, mapping_array):\n",
    "        coherence = PairBasedCoherence(data[np.where(mapping_array == cluster)]).HP\n",
    "        return coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapooc = Rapooc(data,2,2,4)\n",
    "rapooc.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-14:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/a20125359/anaconda3/envs/Biclustering/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/a20125359/anaconda3/envs/Biclustering/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-267-23eec3b67539>\", line 141, in _arg_max_\n",
      "    no_element_h = self._compute_single_h_term_(element_cluster, data, mapping_array)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-269-4ec143f64bc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrapooc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore_coclustering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-267-23eec3b67539>\u001b[0m in \u001b[0;36mcore_coclustering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;31m#join jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Biclustering/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_pid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a child process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'can only join a started process'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0m_children\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Biclustering/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# This shouldn't block if wait() returned successfully.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWNOHANG\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Biclustering/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0;31m# Child process not yet created. See #1731717\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"<ipython-input-267-23eec3b67539>\", line 166, in _compute_single_h_term_\n",
      "    coherence = PairBasedCoherence(data[np.where(mapping_array == cluster)]).HP\n",
      "  File \"<ipython-input-119-a59eefaa546f>\", line 17, in HP\n",
      "    self._HP = self._compute_HP_()\n",
      "  File \"<ipython-input-119-a59eefaa546f>\", line 29, in _compute_HP_\n",
      "    correlation = PositiveNegativeCorrelation(x, y,self._J)\n",
      "  File \"<ipython-input-6-1b51c1b25359>\", line 11, in __init__\n",
      "    self._y_mean = np.mean(y)\n",
      "  File \"/home/a20125359/anaconda3/envs/Biclustering/lib/python3.6/site-packages/numpy/core/fromnumeric.py\", line 2909, in mean\n",
      "    out=out, **kwargs)\n",
      "  File \"/home/a20125359/anaconda3/envs/Biclustering/lib/python3.6/site-packages/numpy/core/_methods.py\", line 66, in _mean\n",
      "    elif issubclass(arr.dtype.type, nt.float16):\n"
     ]
    }
   ],
   "source": [
    "rapooc.core_coclustering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rapooc.bicluster_h_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  2.,  2.,  1.,  1.])"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapooc.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,\n",
       "        2.,  2.,  2.,  2.,  2.])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rapooc.rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "glob.glob('TestData/SimulatedDataCoherence/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.array(np.array([0,1,2,3,3,3,6,7,8]))\n",
    "a = d[np.whe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.013931 ,  0.49935  ],\n",
       "       [ 0.0067908,  0.50297  ]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(data)[np.ix_([0,3],[1,2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,2):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
