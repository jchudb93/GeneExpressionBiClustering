{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three-dimensional STSSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#  %load_ext pycodestyle_magic\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import glob\n",
    "import multiprocessing\n",
    "import copy\n",
    "\n",
    "from operator import attrgetter\n",
    "from sklearn.datasets import make_biclusters\n",
    "from sklearn.datasets import samples_generator as sg\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bicluster(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        rho=None,\n",
    "        gamma=None, \n",
    "        bisected=False,\n",
    "        H_max=None, \n",
    "        best_bisection=None\n",
    "    ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Bicluters structure\n",
    "        \n",
    "        \n",
    "        :param rho: <np.array[int]> the map of the indices of rows of the bicluster i.e [2,4,7,8]\n",
    "        :param gamma: <np.array[int]> the map of gammas, same structure f rho\n",
    "        :param bisected: <boolean> indicates if the bicluster has been bisected recentky\n",
    "        :param h_max: <float> best h from the last bisection\n",
    "        :paran best_bisection: <np.array[int]> mapping array from the best bisection\n",
    "        \n",
    "        *Note: Noise will be represented as -1\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.rho = rho\n",
    "        self.bisected = bisected\n",
    "        self.h_max = H_max\n",
    "        self.bisected_direction = best_bisection.flg_direction if best_bisection is not None else None\n",
    "        self.best_bisection = best_bisection\n",
    "        self.data = data[np.ix_(self.rho, self.gamma)]\n",
    "\n",
    "    def set_bisected(self):\n",
    "        \n",
    "        self.bisected = not self.bisected\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        return (\"rho: \\n\"+ str(self.rho) + \"\\ngamma: \\n\" + str(self.gamma) + \"\\nH: \\n \" + str(self.H))\n",
    "                \n",
    "    def row_length(self):\n",
    "        \n",
    "        return len(self.rho>=0)\n",
    "    \n",
    "    def col_length(self):\n",
    "        \n",
    "        return len(self.gamma>=0)\n",
    "    \n",
    "    def set_fields(self, best_bisection, h_max, bisected_direction):\n",
    "        \n",
    "        \"\"\"\n",
    "        Method\n",
    "        \n",
    "        :param best_bisection: <np.array[int]> Mapping array from the best bisection \n",
    "        :param h_max: <float> Best H from the last bisection\n",
    "        :bisected_direction: <String> Direction from the last bisection ('cols' or 'rows')\n",
    "        \"\"\"\n",
    "        \n",
    "        self.best_bisection = best_bisection\n",
    "        self.h_max = h_max\n",
    "        self.bisected_direction = bisected_direction\n",
    "        final_map = best_bisection == 0 # filtering noise then zeros\n",
    "\n",
    "        if(bisected_direction == 'cols'):\n",
    "            \n",
    "            self.gamma = self.gamma[final_map]\n",
    "            print(self.gamma)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            self.rho = self.rho[final_map]\n",
    "            \n",
    "    def compute_H(self, data):\n",
    "        \n",
    "        \"\"\"\n",
    "        Method:\n",
    "        Computes the coherence H of the data\n",
    "        \"\"\"\n",
    "        \n",
    "        self.data = data[np.ix_(self.rho, self.gamma)]\n",
    "        self.H = three_dimensional_msr(self.data)\n",
    "        \n",
    "        return self.H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cols(data, min_coherence):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function:\n",
    "    Spits the bicluster according to the best split in of columns\n",
    "    \n",
    "    :param data: <np.array[np.array]> data of the bicluster to split\n",
    "    :param bicluster: <Bicluster> data \n",
    "    :param min_coherence: <float> minimal coherence of a bicluster\n",
    "    \"\"\"\n",
    "    \n",
    "    t_data = data.transpose(1,0,2)\n",
    "    aux_I, aux_J = t_data.shape[0:2]\n",
    "    aux_indices = np.zeros(aux_I)\n",
    "    middle = 0\n",
    "    max_h = 0\n",
    "    temp_max = 0\n",
    "    flg_noise_cleaning = False\n",
    "    temp_h_right = 0\n",
    "    temp_h_left = 0\n",
    "    \n",
    "    for i in range(1, aux_I-1):\n",
    "\n",
    "        temp_h_right = three_dimensional_msr(t_data[i:len(t_data)])\n",
    "        temp_h_left = three_dimensional_msr(t_data[0:i+1])\n",
    "        temp_max = max(temp_h_right, temp_h_left)\n",
    "        \n",
    "        if (temp_max >= max_h):\n",
    "            \n",
    "            max_h = temp_max\n",
    "            middle = i\n",
    "            \n",
    "    indices = np.ones(aux_I)\n",
    "    zeros = np.zeros(middle)\n",
    "    \n",
    "    if len(indices) == 1 or temp_h_left <= min_coherence:\n",
    "        indices = np.array(-1*np.ones(len(indices)))\n",
    "        flg_noise_cleaning = True\n",
    "        \n",
    "    if len(zeros) == 1 or temp_h_right <= min_coherence:\n",
    "        zeros = np.array(-1*np.ones(len(zeros)))\n",
    "        flg_noise_cleaning = True\n",
    "        \n",
    "    indices[0:middle] = zeros\n",
    "    indices = np.array(indices)  \n",
    "    unique_indices = np.unique(indices)\n",
    "    \n",
    "    return (indices, max_h, flg_noise_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dm(dm):\n",
    "    dm[dm < 0] = 0\n",
    "    dm = 1-dm**4\n",
    "    np.fill_diagonal(dm, 0)\n",
    "    \n",
    "    return dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(data, min_cluster_size):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply DBSCAN over the bicluster to filter noise\n",
    "    \n",
    "    :param bicluster: <Bicluster> data\n",
    "    :param min_cluster_size\n",
    "    \"\"\"\n",
    "    \n",
    "    n_cols = data.shape[1]\n",
    "    dm = np.asarray([[((three_dimensional_coherence(p1, p2)) \\\n",
    "                       if (three_dimensional_coherence(p1, p2)) \\\n",
    "                       != 1 \\\n",
    "                       else 0.0) \n",
    "                      for p2 in data]\\\n",
    "                     for p1 in data])\n",
    "    dm = transform_dm(dm)\n",
    "    gmm = GaussianMixture(n_components=3)\n",
    "    gmm.fit(np.array([(dm).flatten()]).T)\n",
    "    eps = gmm.means_[np.where(gmm.weights_\\\n",
    "                              ==(min(gmm.weights_)))].flatten()\n",
    "    dev = gmm.covariances_.flatten()[np.where(gmm.weights_\\\n",
    "                                              ==(min(gmm.weights_)))]\n",
    "    lower_bound = 0 #eps - 8*dev\n",
    "    rows = np.array([])\n",
    "    \n",
    "    \n",
    "    while (eps) > lower_bound:\n",
    "        \n",
    "        db = DBSCAN(eps = eps ,metric='precomputed', \n",
    "                    min_samples=min_cluster_size,\n",
    "               ).fit(dm)\n",
    "        \n",
    "        # print(db.labels_)\n",
    "        rows = db.labels_\n",
    "        \n",
    "        if(len(np.unique(db.labels_))<3):\n",
    "            \n",
    "            eps -= dev/4\n",
    "            if eps <= 0:\n",
    "                \n",
    "                eps = 1.0e-15\n",
    "                break\n",
    "        else:\n",
    "            \n",
    "            break\n",
    "\n",
    "    map_array = rows\n",
    "    tmp_bicluster_label = 0\n",
    "    max_h = 0\n",
    "    \n",
    "    for i in np.unique(rows):\n",
    "        \n",
    "        if i == -1:\n",
    "            \n",
    "            pass\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            temp_h = three_dimensional_msr(data[np.where(rows == i)])\n",
    "            \n",
    "            if temp_h >= max_h:\n",
    "                max_h = temp_h\n",
    "                tmp_bicluster_label = i\n",
    "\n",
    "    final_array = np.array([1 if value == tmp_bicluster_label else (0 if value != -1 else -1) \n",
    "                            for value in db.labels_])\n",
    "    map_array = final_array\n",
    "    flg_noise_cleaning = False\n",
    "    unique_array = np.unique(final_array)\n",
    "    \n",
    "    if (len(unique_array) == 2 and unique_array[0] == -1):\n",
    "        \n",
    "        flg_noise_cleaning = True\n",
    "    \n",
    "    new_map = map_array\n",
    "        \n",
    "    if ((np.unique(map_array)[0] == -1) and len(np.unique(map_array)) == 1):\n",
    "        \n",
    "        print(\"all negatives\", len(map_array))\n",
    "        new_map = np.ones(int(len(map_array)))\n",
    "        zeros = np.zeros(int(len(map_array)/2))\n",
    "        new_map[0:int(len(map_array)/2)] = zeros\n",
    "        # print(new_map)\n",
    "        flg_noise_cleaning = False\n",
    "        map_array = new_map.copy()\n",
    "        max_h = 0\n",
    "    \n",
    "    return (map_array, max_h, flg_noise_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bicluster_coherence(bicluster, \n",
    "                                min_cluster_row_size,\n",
    "                                min_coherence):\n",
    "    \n",
    "    \"\"\"\n",
    "    Splits bicluster and chooses wether its better to split rows or columns\n",
    "    \n",
    "    :param bicluster: <Bicluster> Bicluster to split\n",
    "    :param min_coherence: <float> minimal coherence of a bicluster\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Compute Coherence\")\n",
    "    \n",
    "    flg_noise_cleaning_rows = False\n",
    "    flg_noise_cleaning_cols = False\n",
    "    \n",
    "    if (bicluster.bisected):\n",
    "    \n",
    "        return (bicluster.best_bisection, bicluster.h_max, bicluster.bisected_direction)\n",
    "    else:\n",
    "        \n",
    "        map_array_cols, h_cols, flg_noise_cleaning_cols = split_cols(bicluster.data, min_coherence=min_coherence)\n",
    "        map_array_rows, h_rows, flg_noise_cleaning_rows = split_rows(bicluster.data, min_cluster_row_size)\n",
    "        print(\"\\nmap array rows len \", len(map_array_rows))\n",
    "        # print(\"h cols \" + str(h_cols) + \" h rows \" + str(h_rows))\n",
    "        \n",
    "        if (h_cols > h_rows):\n",
    "            \n",
    "            if flg_noise_cleaning_cols:\n",
    "                \n",
    "                return (map_array_cols, h_cols, \"clean cols\")\n",
    "            else:\n",
    " \n",
    "                return (map_array_cols, h_cols, \"cols\")\n",
    "        else:\n",
    "            \n",
    "            if flg_noise_cleaning_rows:\n",
    "                \n",
    "                return (map_array_rows, h_rows, \"clean rows\")\n",
    "            \n",
    "            return (map_array_rows, h_rows, \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STSSCAN(object):\n",
    "\n",
    "    def __init__(self, data, n_clusters=2, min_coherence = 0.9):\n",
    "        \"\"\"\n",
    "        STSSCAN\n",
    "        \n",
    "        Applies biclustering over data\n",
    "        \n",
    "        :param data: <np.array> The data to apply biclusters\n",
    "        :param n_clusters: <int> The number of biclusters to find\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        assert data is not None, 'Empty data'\n",
    "        self._data = data\n",
    "        (self._I, self._J) = self._data.shape[0:2]\n",
    "        self._n_clusters = n_clusters\n",
    "        self._biclusters = list()\n",
    "        self._objective_function = 0\n",
    "        self._min_coherence = min_coherence\n",
    "\n",
    "    @property\n",
    "    def n_clusters(self):\n",
    "        return self._n_clusters\n",
    "\n",
    "    @property\n",
    "    def data(self):\n",
    "        return self._data\n",
    "\n",
    "    @property\n",
    "    def biclusters(self):\n",
    "        return self._biclusters\n",
    "\n",
    "    def fit(self):\n",
    "        \"\"\"\n",
    "        Fits the data on the algorithm. Iters over the \n",
    "        number of biclusters until find the requested number\n",
    "        \"\"\"\n",
    "\n",
    "        print ('Fitting data ')\n",
    "        n_iterations = 0\n",
    "        n_clusters = self._n_clusters\n",
    "        initial_bicluster = Bicluster(self._data, np.arange(self._I),\n",
    "                np.arange(self._J))\n",
    "        self._biclusters.append(initial_bicluster)\n",
    "        \n",
    "        while len(self._biclusters) != self.n_clusters:\n",
    "            \n",
    "            print('\\nN iteration ' + str(n_iterations))\n",
    "            \n",
    "            self._split_biclusters() \n",
    "            n_iterations += 1\n",
    "        # self._prune()\n",
    "\n",
    "    def _split_biclusters(self):\n",
    "        \"\"\"\n",
    "        Splits bicluters in order to find the next biclusters that optimizes\n",
    "        the sum of coherences among biclusters\n",
    "        \"\"\"\n",
    "\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "\n",
    "        print()\n",
    "        print('Splitting biclusters ')\n",
    "\n",
    "        h_max = 0\n",
    "        tmp_bicluster_delta = 0\n",
    "        tmp_bisection = None\n",
    "        tmp_split = 'cols'\n",
    "        tmp_bisection_direction = None\n",
    "        position = 0\n",
    "        best_position = 0\n",
    "        best_bisection_array = np.array([])\n",
    "        best_bisection_direction = None\n",
    "\n",
    "        while position != len(self._biclusters):\n",
    "\n",
    "            bicluster = self._biclusters[position]\n",
    "            \n",
    "            print()\n",
    "            \n",
    "            print('Position ' + str(position))\n",
    "            \n",
    "            print('\\nRow length ' + str(bicluster.row_length()) + ' Col length ' + str(bicluster.col_length()) + '\\n')\n",
    "            \n",
    "            min_cluster_row_size = math.floor(np.log(self._I) * 5)\n",
    "\n",
    "            if bicluster.row_length() >= min_cluster_row_size and bicluster.col_length() > 3:\n",
    "\n",
    "                (tmp_bisection, tmp_bicluster_delta, tmp_split) = compute_bicluster_coherence(bicluster, min_cluster_row_size, self._min_coherence)\n",
    "\n",
    "                if tmp_split == 'clean cols':\n",
    "\n",
    "                    index_map = tmp_bisection.copy() >= 0\n",
    "                    rho = self._biclusters[position].rho.copy()\n",
    "                    new_gamma = self._biclusters[position].gamma.copy()[index_map]\n",
    "                    self._biclusters[position] = Bicluster(self._data,\n",
    "                            rho, new_gamma)\n",
    "                    best_bisection_direction = 'clean'\n",
    "                    \n",
    "                    print('\\nCleaned cols at ' + str(position))\n",
    "                    \n",
    "                elif tmp_split == 'clean rows':\n",
    "\n",
    "                    index_map = tmp_bisection.copy() >= 0\n",
    "                    rho = self._biclusters[position].rho.copy()[index_map]\n",
    "                    new_gamma = self._biclusters[position].gamma.copy()\n",
    "                    self._biclusters[position] = Bicluster(self._data,\n",
    "                            rho, new_gamma)\n",
    "                    best_bisection_direction = 'clean'\n",
    "                    print('\\nCleaned rows at ' + str(position))\n",
    "                else:\n",
    "\n",
    "                    if tmp_bicluster_delta >= h_max:\n",
    "                        \n",
    "                        h_max = tmp_bicluster_delta\n",
    "                        best_position = position\n",
    "                        best_bisection_array = tmp_bisection.copy()\n",
    "                        best_bisection_direction = ('cols'\n",
    "                                 if tmp_split == 'cols' else 'rows')\n",
    "            position += 1\n",
    "\n",
    "        if best_bisection_direction != 'clean':\n",
    "            \n",
    "            print('\\nBisected bicluster at ' + str(best_position))\n",
    "            best_bisection = best_bisection_array\n",
    "            self._add_bicluster(best_position, best_bisection, h_max,\n",
    "                                best_bisection_direction)\n",
    "\n",
    "    def _add_bicluster(\n",
    "        self,\n",
    "        best_position,\n",
    "        best_bisection,\n",
    "        h_max,\n",
    "        bisection_direction,\n",
    "        ):\n",
    "        \n",
    "        \"\"\"\n",
    "        Adds the found bicluster into the list of labels\n",
    "        \n",
    "        :param best_position: <int> position of the best bicluster\n",
    "        :param best_bisection: <np.array[int]> map_array of the best bisection\n",
    "        :param max_delta: h_max \n",
    "        \"\"\"\n",
    "\n",
    "        # Create the new bicluster\n",
    "\n",
    "        best_rho = self._biclusters[best_position].rho\n",
    "        best_gamma = self._biclusters[best_position].gamma\n",
    "        index_map = best_bisection >= 1\n",
    "        aux_index_map = best_bisection == 0\n",
    "        \n",
    "        if bisection_direction == 'cols':\n",
    "            \n",
    "            new_rho = best_rho.copy()\n",
    "            new_gamma = best_gamma[index_map].copy()\n",
    "            aux_rho = best_rho.copy()\n",
    "            aux_gamma = best_gamma[aux_index_map].copy()\n",
    "            \n",
    "            # print('\\nAdded bicluster cols: ' + str(new_gamma))\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            new_gamma = best_gamma.copy()\n",
    "            new_rho = best_rho[index_map].copy()\n",
    "            aux_rho = best_rho[aux_index_map].copy()\n",
    "            aux_gamma = best_gamma.copy()\n",
    "            \n",
    "            # print('\\nAdded bicluster rows: ' + str(new_rho))\n",
    "            \n",
    "        new_bicluster = Bicluster(self._data, new_rho, new_gamma)\n",
    "\n",
    "        self._biclusters.append(new_bicluster)\n",
    "\n",
    "        # Modify the bicluster that is going to be bisected\n",
    "\n",
    "        self._biclusters[best_position] = Bicluster(self._data, aux_rho, aux_gamma)\n",
    "\n",
    "    def _prune(self):\n",
    "\n",
    "        for position in range(0, len(self._biclusters)):\n",
    "\n",
    "            print(position)\n",
    "\n",
    "            rho = self._biclusters[position].rho\n",
    "            gamma = self._biclusters[position].gamma\n",
    "\n",
    "            if len(gamma) > 0:\n",
    "\n",
    "                stds = np.std(self._data[np.ix_(rho, gamma)], axis=0)\n",
    "                std = np.mean(stds)\n",
    "                lst_map = list()\n",
    "\n",
    "                print('std ' + str(std))\n",
    "\n",
    "                for index in [0, len(stds) - 1]:\n",
    "                    \n",
    "                    if stds[index] <= std * 2:\n",
    "                        \n",
    "                        lst_map.append(1)\n",
    "                    else:\n",
    "                        \n",
    "                        lst_map.append(0)\n",
    "\n",
    "                print(lst_map)\n",
    "    \n",
    "    def merge(self):\n",
    "        \n",
    "        index = 0\n",
    "        \n",
    "        for index in range(0,len(self._biclusters)):\n",
    "            \n",
    "            sub_index = 0\n",
    "            \n",
    "            for sub_index in range(index+1,len(self._biclusters)):\n",
    "                \n",
    "                if (max(self._biclusters[index].gamma) == min(self._biclusters[sub_index].gamma) and \n",
    "                    self._biclusters[index].rho == self._biclusters[sub_index].rho\n",
    "                   ):\n",
    "                    \n",
    "                    print(\"Merge \" + str(index) + \" with \" + str(sub_index)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CauseGene</th>\n",
       "      <th>EffectGene</th>\n",
       "      <th>Replicate</th>\n",
       "      <th>Treatment</th>\n",
       "      <th>Pvalue</th>\n",
       "      <th>0min_neg_cause</th>\n",
       "      <th>15min_cause</th>\n",
       "      <th>30min_cause</th>\n",
       "      <th>90min_cause</th>\n",
       "      <th>120min_cause</th>\n",
       "      <th>...</th>\n",
       "      <th>360min_cause</th>\n",
       "      <th>0min_neg_effect</th>\n",
       "      <th>15min_effect</th>\n",
       "      <th>30min_effect</th>\n",
       "      <th>90min_effect</th>\n",
       "      <th>120min_effect</th>\n",
       "      <th>180min_effect</th>\n",
       "      <th>210min_effect</th>\n",
       "      <th>240min_effect</th>\n",
       "      <th>360min_effect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NFKB1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>1</td>\n",
       "      <td>BCR</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.795316</td>\n",
       "      <td>-1.266743</td>\n",
       "      <td>-0.755123</td>\n",
       "      <td>-0.128786</td>\n",
       "      <td>1.102735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033916</td>\n",
       "      <td>0.077473</td>\n",
       "      <td>-0.044090</td>\n",
       "      <td>-0.349988</td>\n",
       "      <td>-0.122733</td>\n",
       "      <td>-0.027860</td>\n",
       "      <td>1.066276</td>\n",
       "      <td>0.106499</td>\n",
       "      <td>-1.334779</td>\n",
       "      <td>0.580358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NFKB1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>1</td>\n",
       "      <td>CD40</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.795316</td>\n",
       "      <td>-0.933564</td>\n",
       "      <td>-1.153256</td>\n",
       "      <td>-0.453810</td>\n",
       "      <td>0.306257</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486948</td>\n",
       "      <td>0.077473</td>\n",
       "      <td>0.255573</td>\n",
       "      <td>0.825101</td>\n",
       "      <td>-2.091418</td>\n",
       "      <td>0.986115</td>\n",
       "      <td>0.020539</td>\n",
       "      <td>0.666451</td>\n",
       "      <td>-0.667305</td>\n",
       "      <td>0.313519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NFKB1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>2</td>\n",
       "      <td>BCR</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.920032</td>\n",
       "      <td>-1.316489</td>\n",
       "      <td>-0.880604</td>\n",
       "      <td>1.696180</td>\n",
       "      <td>0.905204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165541</td>\n",
       "      <td>-0.670996</td>\n",
       "      <td>0.537398</td>\n",
       "      <td>0.592462</td>\n",
       "      <td>0.456636</td>\n",
       "      <td>-0.244272</td>\n",
       "      <td>-1.993159</td>\n",
       "      <td>0.945375</td>\n",
       "      <td>0.301992</td>\n",
       "      <td>1.030175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NFKB1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>2</td>\n",
       "      <td>CD40</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-0.920032</td>\n",
       "      <td>-1.807573</td>\n",
       "      <td>-0.904500</td>\n",
       "      <td>0.134772</td>\n",
       "      <td>0.357957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.573824</td>\n",
       "      <td>-0.670996</td>\n",
       "      <td>1.808573</td>\n",
       "      <td>-1.767904</td>\n",
       "      <td>-0.623801</td>\n",
       "      <td>-0.330098</td>\n",
       "      <td>1.473550</td>\n",
       "      <td>-0.284614</td>\n",
       "      <td>-1.346430</td>\n",
       "      <td>0.232617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NFKB1</td>\n",
       "      <td>A1BG</td>\n",
       "      <td>3</td>\n",
       "      <td>BCR</td>\n",
       "      <td>0.691</td>\n",
       "      <td>-1.647137</td>\n",
       "      <td>-0.852110</td>\n",
       "      <td>-0.858377</td>\n",
       "      <td>0.918947</td>\n",
       "      <td>0.929054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030287</td>\n",
       "      <td>1.650800</td>\n",
       "      <td>0.196474</td>\n",
       "      <td>-0.110119</td>\n",
       "      <td>-1.663191</td>\n",
       "      <td>0.131282</td>\n",
       "      <td>-0.023995</td>\n",
       "      <td>-0.201010</td>\n",
       "      <td>1.363202</td>\n",
       "      <td>1.410923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CauseGene EffectGene  Replicate Treatment  Pvalue  0min_neg_cause  \\\n",
       "0     NFKB1       A1BG          1       BCR   0.691       -0.795316   \n",
       "1     NFKB1       A1BG          1      CD40   0.691       -0.795316   \n",
       "2     NFKB1       A1BG          2       BCR   0.691       -0.920032   \n",
       "3     NFKB1       A1BG          2      CD40   0.691       -0.920032   \n",
       "4     NFKB1       A1BG          3       BCR   0.691       -1.647137   \n",
       "\n",
       "   15min_cause  30min_cause  90min_cause  120min_cause      ...        \\\n",
       "0    -1.266743    -0.755123    -0.128786      1.102735      ...         \n",
       "1    -0.933564    -1.153256    -0.453810      0.306257      ...         \n",
       "2    -1.316489    -0.880604     1.696180      0.905204      ...         \n",
       "3    -1.807573    -0.904500     0.134772      0.357957      ...         \n",
       "4    -0.852110    -0.858377     0.918947      0.929054      ...         \n",
       "\n",
       "   360min_cause  0min_neg_effect  15min_effect  30min_effect  90min_effect  \\\n",
       "0      0.033916         0.077473     -0.044090     -0.349988     -0.122733   \n",
       "1     -0.486948         0.077473      0.255573      0.825101     -2.091418   \n",
       "2      0.165541        -0.670996      0.537398      0.592462      0.456636   \n",
       "3     -0.573824        -0.670996      1.808573     -1.767904     -0.623801   \n",
       "4     -0.030287         1.650800      0.196474     -0.110119     -1.663191   \n",
       "\n",
       "   120min_effect  180min_effect  210min_effect  240min_effect  360min_effect  \n",
       "0      -0.027860       1.066276       0.106499      -1.334779       0.580358  \n",
       "1       0.986115       0.020539       0.666451      -0.667305       0.313519  \n",
       "2      -0.244272      -1.993159       0.945375       0.301992       1.030175  \n",
       "3      -0.330098       1.473550      -0.284614      -1.346430       0.232617  \n",
       "4       0.131282      -0.023995      -0.201010       1.363202       1.410923  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/Raw/Ikk2.csv\", sep=\";\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"../data/Raw/Erk.csv\", sep=\";\")\n",
    "neg_data = data[data[\"Pvalue\"]>0.5]\n",
    "pos_data = data[(data[\"Pvalue\"]<=0.01)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative  104256  positive  4548\n"
     ]
    }
   ],
   "source": [
    "print(\"negative \", len(neg_data), \" positive \", len(pos_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_data = pos_data.sample(frac=0.2)\n",
    "neg_data = neg_data.sample(frac=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = data[data.columns[5:]].max().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_value = data[data.columns[5:]].min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(pos_data, train_size=0.9)\n",
    "neg_test = neg_data.sample(len(train) + len(test))\n",
    "train_cause = train[train.columns[5:14]]\n",
    "train_cause = (train_cause - max_value) / (min_value - max_value)\n",
    "train_effect = train[train.columns[14:]]\n",
    "train_effect = (train_effect - max_value) / (min_value - max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test = neg_data.sample((len(train) + len(test))*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cause = test[test.columns[5:14]]\n",
    "test_cause = (test_cause - max_value) / (min_value - max_value)\n",
    "test_effect = test[test.columns[14:]]\n",
    "test_effect = (test_effect -max_value) / (min_value - max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_cause = neg_test[neg_test.columns[5:14]]\n",
    "neg_cause = (neg_cause - max_value) / (min_value - max_value)\n",
    "neg_effect = neg_test[neg_test.columns[14:]]\n",
    "neg_effect = (neg_effect - max_value) / (min_value - max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_test[['CauseGene','EffectGene']].sample(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trajectories = list()\n",
    "\n",
    "for i in range(len(train_cause.columns)):\n",
    "    \n",
    "    train_trajectories.append(np.dstack((train_cause[train_cause.columns[i]], \n",
    "                                         train_effect[train_effect.columns[i]]))[0]\n",
    "                             )\n",
    "train_trajectories = np.transpose(np.array(train_trajectories),[1,0,2])\n",
    "train_trajectories = np.array(train_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_trajectories = list()\n",
    "\n",
    "for i in range(len(neg_cause.columns)):\n",
    "    \n",
    "    neg_trajectories.append(np.dstack((neg_cause[neg_cause.columns[i]],\n",
    "                                      neg_effect[neg_effect.columns[i]]))[0]\n",
    "                           )\n",
    "neg_trajectories = np.transpose(np.array(neg_trajectories),[1, 0, 2])\n",
    "neg_trajectories = np.array(neg_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trajectories = list()\n",
    "\n",
    "for i in range(len(test_cause.columns)):\n",
    "    \n",
    "    test_trajectories.append(np.dstack((test_cause[test_cause.columns[i]],\n",
    "                                      test_effect[test_effect.columns[i]]))[0]\n",
    "                           )\n",
    "test_trajectories = np.transpose(np.array(test_trajectories),[1, 0, 2])\n",
    "test_trajectories = np.array(test_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_biclusters(stsscan):\n",
    "    \n",
    "    for i in range(len(stsscan.biclusters)):\n",
    "        print()\n",
    "        print(\"bicluster \", i)\n",
    "        print(\"rho:\\n\", stsscan.biclusters[i].rho, \"\\n\\ngamma:\\n\", stsscan.biclusters[i].gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsscan2 = STSSCAN(train_trajectories, 2, 0.7)\n",
    "stscan2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsscan2.biclusters[1].gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsscan3 = STSSCAN(train_trajectories, 3, 0.7)\n",
    "stsscan3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsscan4 = STSSCAN(train_trajectories, 4, 0.7)\n",
    "stsscan4.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsscan5 = STSSCAN(train_trajectories, 5, 0.7)\n",
    "stsscan5.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminative biclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_trajectory(bicluster):\n",
    "    \n",
    "    average_trajectory = np.array([np.mean(bicluster.data[:,i], axis = 0) \n",
    "                                   for i in range(bicluster.data.shape[1])])\n",
    "    \n",
    "    return average_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_average_trajectory(stsscan2.biclusters[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_coherence(avg_trajectory, bicluster):\n",
    "    \n",
    "    acc = 0.0\n",
    "    data = bicluster.data\n",
    "    deviation = list()\n",
    "    for i in range(data.shape[0]-1):\n",
    "        \n",
    "        acc += three_dimensional_coherence(avg_trajectory, data[i])\n",
    "        deviation.append(three_dimensional_coherence(avg_trajectory, data[i]))\n",
    "    deviation = np.array(deviation)\n",
    "    return (acc/(data.shape[0]*1.0), np.std(deviation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminative_score(pos_data, bicluster, neg_data):\n",
    "    \n",
    "    avg_trajectory = compute_average_trajectory(bicluster)\n",
    "    avg_coherence, std_coherence = compute_average_coherence(avg_trajectory, bicluster)\n",
    "    pos_rate = 1.0 * ((len(bicluster.rho) * len(bicluster.gamma))/(pos_data.shape[0] * pos_data.shape[1]))\n",
    "    test_data = neg_data[:, bicluster.gamma]\n",
    "    print(std_coherence)\n",
    "    print(\"len gamma\", len(bicluster.gamma))\n",
    "    print(\"neg data shape\", neg_data.shape)\n",
    "    neg_instances = 0\n",
    "    \n",
    "    for i in range(test_data.shape[0]):\n",
    "        \n",
    "        correlation = three_dimensional_coherence(test_data[i], avg_trajectory)\n",
    "        \n",
    "        if avg_coherence + std_coherence * 1.5 < correlation:\n",
    "            \n",
    "            neg_instances += 1\n",
    "            \n",
    "    print(\"neg instances\", neg_instances)\n",
    "    neg_rate = 1.0 * ((neg_instances*len(bicluster.gamma)) / (neg_data.shape[0] * neg_data.shape[1]))\n",
    "    \n",
    "    print(\"positive rate\", pos_rate, \" negative rate \", neg_rate)\n",
    "    return (pos_rate >= neg_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_stsscan = [stsscan3, stsscan4, stsscan5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stsscan2.biclusters[0].gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.000435633108362\n",
      "len gamma 7\n",
      "neg data shape (237, 9, 2)\n",
      "neg instances 237\n",
      "positive rate 0.7777777777777778  negative rate  0.7777777777777778\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminative_score(train_trajectories, stsscan2.biclusters[0], train_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_membership_stsscan(lst_stsscan, positive, negative):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for sts in lst_stsscan:\n",
    "        \n",
    "        print(\"\\nsts n°\", i)\n",
    "        b = 0\n",
    "        \n",
    "        for bicluster in sts.biclusters:\n",
    "            \n",
    "            print(\"\\nbicluster n°\", b, \"\\n\")\n",
    "            \n",
    "            if (discriminative_score(positive, bicluster, negative)):\n",
    "                \n",
    "                print(\"\\ndiscriminant bicluster\")\n",
    "            else:\n",
    "                \n",
    "                print(\"\\non discriminant bicluster\")\n",
    "                \n",
    "            b += 1\n",
    "            \n",
    "        i += 1\n",
    "            \n",
    "        print(\"=============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2640"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sts n° 0\n",
      "\n",
      "bicluster n° 0 \n",
      "\n",
      "0.000435633108362\n",
      "len gamma 7\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.7777777777777778  negative rate  0.7777777777777778\n",
      "\n",
      "discriminant bicluster\n",
      "\n",
      "bicluster n° 1 \n",
      "\n",
      "0.00067880289349\n",
      "len gamma 2\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2628\n",
      "positive rate 0.2222222222222222  negative rate  0.22121212121212122\n",
      "\n",
      "discriminant bicluster\n",
      "=============================\n",
      "\n",
      "sts n° 1\n",
      "\n",
      "bicluster n° 0 \n",
      "\n",
      "0.000211008745351\n",
      "len gamma 7\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.33802156586966714  negative rate  0.7777777777777778\n",
      "\n",
      "on discriminant bicluster\n",
      "\n",
      "bicluster n° 1 \n",
      "\n",
      "0.00067880289349\n",
      "len gamma 2\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2628\n",
      "positive rate 0.2222222222222222  negative rate  0.22121212121212122\n",
      "\n",
      "discriminant bicluster\n",
      "\n",
      "bicluster n° 2 \n",
      "\n",
      "0.000123297422619\n",
      "len gamma 7\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.07876230661040788  negative rate  0.7777777777777778\n",
      "\n",
      "on discriminant bicluster\n",
      "=============================\n",
      "\n",
      "sts n° 2\n",
      "\n",
      "bicluster n° 0 \n",
      "\n",
      "0.000258511472319\n",
      "len gamma 5\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.2414439756211908  negative rate  0.5555555555555556\n",
      "\n",
      "on discriminant bicluster\n",
      "\n",
      "bicluster n° 1 \n",
      "\n",
      "0.00067880289349\n",
      "len gamma 2\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2628\n",
      "positive rate 0.2222222222222222  negative rate  0.22121212121212122\n",
      "\n",
      "discriminant bicluster\n",
      "\n",
      "bicluster n° 2 \n",
      "\n",
      "0.000123297422619\n",
      "len gamma 7\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.07876230661040788  negative rate  0.7777777777777778\n",
      "\n",
      "on discriminant bicluster\n",
      "\n",
      "bicluster n° 3 \n",
      "\n",
      "0.000190609155382\n",
      "len gamma 2\n",
      "neg data shape (2640, 9, 2)\n",
      "neg instances 2640\n",
      "positive rate 0.09657759024847633  negative rate  0.2222222222222222\n",
      "\n",
      "on discriminant bicluster\n",
      "=============================\n",
      "\n",
      "sts n° 3\n",
      "\n",
      "bicluster n° 0 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a20125359/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/a20125359/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py:73: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-4e566fbd50ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manalyze_membership_stsscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlst_stsscan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_trajectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_trajectories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-98-77b9af353919>\u001b[0m in \u001b[0;36manalyze_membership_stsscan\u001b[0;34m(lst_stsscan, positive, negative)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nbicluster n°\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiscriminative_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\ndiscriminant bicluster\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-94-94fb543bda90>\u001b[0m in \u001b[0;36mdiscriminative_score\u001b[0;34m(pos_data, bicluster, neg_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mavg_trajectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_average_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbicluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mavg_coherence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd_coherence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_average_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_trajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpos_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbicluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbicluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpos_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneg_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbicluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-b9e9c2a25855>\u001b[0m in \u001b[0;36mcompute_average_coherence\u001b[0;34m(avg_trajectory, bicluster)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdeviation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthree_dimensional_coherence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_trajectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdeviation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeviation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeviation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "analyze_membership_stsscan(lst_stsscan, train_trajectories, neg_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_membership_scores(trajectory, bicluster, mean_trajectory):\n",
    "    \n",
    "    def compute_deviation(column, mean_coord):\n",
    "        \n",
    "        distances = np.array([distance.euclidean(row, mean_coord) for row in column])\n",
    "        \n",
    "        return np.std(distances)\n",
    "        \n",
    "        \n",
    "    scores = list()\n",
    "    j=0\n",
    "    biclusterT = np.transpose(bicluster.data,[1,0,2])\n",
    "    \n",
    "    for column in biclusterT:\n",
    "        \n",
    "        deviation = compute_deviation(column, mean_trajectory[j])\n",
    "        norm = np.linalg.norm(trajectory[j] - mean_trajectory[j])\n",
    "        score = min(deviation/norm, 1)\n",
    "        scores.append(score)\n",
    "        j += 1\n",
    "        \n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def member(tc, bicluster):\n",
    "    # print(bicluster.gamma)\n",
    "    _tc = tc[bicluster.gamma]\n",
    "    _bicluster = bicluster\n",
    "    mean_trajectory = bicluster.data.mean(axis=0)\n",
    "    scores = compute_membership_scores(_tc, bicluster, mean_trajectory)\n",
    "    total_membership_score = 1.0 - ((1 / len(tc)) *sum(scores))\n",
    "    \n",
    "    return total_membership_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(trajectories, stsscan):\n",
    "    \n",
    "    i = 0\n",
    "    \n",
    "    for trajectory in trajectories:\n",
    "        print(\"\\ntrajectory: \", i)\n",
    "        b = 0\n",
    "        total_score = 0\n",
    "        scores = list()\n",
    "        for bicluster in [stsscan.biclusters[1],stsscan.biclusters[0]] :\n",
    "                \n",
    "                total_score += member(trajectory, bicluster)\n",
    "                scores.append(member(trajectory, bicluster))\n",
    "                b += 1\n",
    "                \n",
    "        print(\"\\ntotal_score: \", total_score/b, \" max score \", max(scores))\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "trajectory:  0\n",
      "\n",
      "total_score:  0.719497332605  max score  0.860121077961\n",
      "\n",
      "trajectory:  1\n",
      "\n",
      "total_score:  0.71392138871  max score  0.808728448558\n",
      "\n",
      "trajectory:  2\n",
      "\n",
      "total_score:  0.712768483583  max score  0.913595128526\n",
      "\n",
      "trajectory:  3\n",
      "\n",
      "total_score:  0.673243175687  max score  0.871243140496\n",
      "\n",
      "trajectory:  4\n",
      "\n",
      "total_score:  0.707293634774  max score  0.941928614978\n",
      "\n",
      "trajectory:  5\n",
      "\n",
      "total_score:  0.595648218266  max score  0.803473433033\n",
      "\n",
      "trajectory:  6\n",
      "\n",
      "total_score:  0.669627400254  max score  0.861121928679\n",
      "\n",
      "trajectory:  7\n",
      "\n",
      "total_score:  0.68419809962  max score  0.827490258584\n",
      "\n",
      "trajectory:  8\n",
      "\n",
      "total_score:  0.646261094232  max score  0.860492436581\n",
      "\n",
      "trajectory:  9\n",
      "\n",
      "total_score:  0.666158219875  max score  0.886291114297\n",
      "\n",
      "trajectory:  10\n",
      "\n",
      "total_score:  0.753472762062  max score  0.931161499352\n",
      "\n",
      "trajectory:  11\n",
      "\n",
      "total_score:  0.665645242425  max score  0.933935462441\n",
      "\n",
      "trajectory:  12\n",
      "\n",
      "total_score:  0.675481221038  max score  0.864792210533\n",
      "\n",
      "trajectory:  13\n",
      "\n",
      "total_score:  0.651885750218  max score  0.874997976904\n",
      "\n",
      "trajectory:  14\n",
      "\n",
      "total_score:  0.692261839365  max score  0.829379772997\n",
      "\n",
      "trajectory:  15\n",
      "\n",
      "total_score:  0.665760385408  max score  0.870977658481\n",
      "\n",
      "trajectory:  16\n",
      "\n",
      "total_score:  0.767130073668  max score  0.912779966068\n",
      "\n",
      "trajectory:  17\n",
      "\n",
      "total_score:  0.660540593314  max score  0.853551436765\n",
      "\n",
      "trajectory:  18\n",
      "\n",
      "total_score:  0.668980381251  max score  0.872096404993\n",
      "\n",
      "trajectory:  19\n",
      "\n",
      "total_score:  0.612747745161  max score  0.832304242458\n",
      "\n",
      "trajectory:  20\n",
      "\n",
      "total_score:  0.647667157071  max score  0.843069687224\n",
      "\n",
      "trajectory:  21\n",
      "\n",
      "total_score:  0.67478423348  max score  0.777777777778\n",
      "\n",
      "trajectory:  22\n",
      "\n",
      "total_score:  0.651482077734  max score  0.82949960034\n",
      "\n",
      "trajectory:  23\n",
      "\n",
      "total_score:  0.674714385525  max score  0.849553353559\n",
      "\n",
      "trajectory:  24\n",
      "\n",
      "total_score:  0.749058333665  max score  0.91661537335\n",
      "\n",
      "trajectory:  25\n",
      "\n",
      "total_score:  0.607379539548  max score  0.826255590233\n",
      "\n",
      "trajectory:  26\n",
      "\n",
      "total_score:  0.701488933338  max score  0.883218857662\n"
     ]
    }
   ],
   "source": [
    "classify(test_trajectories, stsscan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'sample'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-321-f912ba54bed0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneg_trajectories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstsscan2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'sample'"
     ]
    }
   ],
   "source": [
    "classify(neg_trajectories.sample(17), stsscan2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lst_stsscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_msr(biclusters):\n",
    "    \n",
    "    total = 0\n",
    "    for b in biclusters:\n",
    "        \n",
    "        total += three_dimensional_msr(b.data)\n",
    "        \n",
    "    return (total / len(biclusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "stscan n:  0\n",
      "\n",
      " mean coherence:  0.997112806209\n",
      "\n",
      "stscan n:  1\n",
      "\n",
      " mean coherence:  0.997543717766\n",
      "\n",
      "stscan n:  2\n",
      "\n",
      " mean coherence:  0.998396163106\n",
      "\n",
      "stscan n:  3\n",
      "\n",
      " mean coherence:  0.998702453873\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for stsscan in lst_stsscan:    \n",
    "\n",
    "    print(\"\\nstscan n: \", i)\n",
    "    print(\"\\n mean coherence: \", mean_msr(stsscan.biclusters))\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
